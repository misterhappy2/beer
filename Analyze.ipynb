{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYZE\n",
    "the data\n",
    "\n",
    "This is a work in progress  \n",
    "\n",
    "Vectorize the data in beer.review  \n",
    "Diminish the importance of common words  \n",
    "Compare ML algorithms to use the review data to predict beer.style  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 80818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brewery</th>\n",
       "      <th>style</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Rock Ale</td>\n",
       "      <td>Big Rock Brewery</td>\n",
       "      <td>Scottish Ale</td>\n",
       "      <td>3.90</td>\n",
       "      <td>smell  soft hop aroma with significant malt scents. this one smells very creamy. taste  and creamy it is. the traditional irish flavors come out at the tongue. this is creamy, not like a cream ale, but close. the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flip Ale</td>\n",
       "      <td>Dogfish Head Craft Brewery</td>\n",
       "      <td>Old Ale</td>\n",
       "      <td>4.08</td>\n",
       "      <td>on tap at dfh rehoboth... collab with eatily... cardamom and red wine must. golden orange. .no head. typical dfh yeast aroma. ..some spice and maybe a belgian influence. sweet spicy and somewhat fruity.. not much ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Almond Marzen Project - Beer Camp #26</td>\n",
       "      <td>Sierra Nevada Brewing Co.</td>\n",
       "      <td>Märzen / Oktoberfest</td>\n",
       "      <td>3.78</td>\n",
       "      <td>nice auburn impressions, tons of clarity, solid inch of off white head.   aroma was a little bit sweet and nutty. taste gave a little more sweetness, stayed away from hops and bitterness, relatively light bodied.  no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        name                     brewery  \\\n",
       "0                               Big Rock Ale            Big Rock Brewery   \n",
       "1                                   Flip Ale  Dogfish Head Craft Brewery   \n",
       "2  The Almond Marzen Project - Beer Camp #26   Sierra Nevada Brewing Co.   \n",
       "\n",
       "                  style  rating  \\\n",
       "0          Scottish Ale    3.90   \n",
       "1               Old Ale    4.08   \n",
       "2  Märzen / Oktoberfest    3.78   \n",
       "\n",
       "                                                                                                                                                                                                                        review  \n",
       "0  smell  soft hop aroma with significant malt scents. this one smells very creamy. taste  and creamy it is. the traditional irish flavors come out at the tongue. this is creamy, not like a cream ale, but close. the m...  \n",
       "1   on tap at dfh rehoboth... collab with eatily... cardamom and red wine must. golden orange. .no head. typical dfh yeast aroma. ..some spice and maybe a belgian influence. sweet spicy and somewhat fruity.. not much ol...  \n",
       "2  nice auburn impressions, tons of clarity, solid inch of off white head.   aroma was a little bit sweet and nutty. taste gave a little more sweetness, stayed away from hops and bitterness, relatively light bodied.  no...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORT MODULES AND THE DATA SET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('beer.csv', header=0)\n",
    "df_copy = df  #save a copy of dataframe for reference. \n",
    "print('length',len(df))\n",
    "pd.set_option('max_colwidth', 220)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df original length 80818\n",
      "length without short reviews 49141\n",
      "length without uncommon styles 47555\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brewery</th>\n",
       "      <th>style</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Rock Ale</td>\n",
       "      <td>Big Rock Brewery</td>\n",
       "      <td>Scottish Ale</td>\n",
       "      <td>3.90</td>\n",
       "      <td>smell  soft hop aroma with significant malt scents. this one smells very creamy. taste  and creamy it is. the traditional irish flavors come out at the tongue. this is creamy, not like a cream ale, but close. the m...</td>\n",
       "      <td>smell soft hop aroma significant malt scents one smells creamy taste creamy traditional irish flavors come tongue creamy like cream ale close malt big buttery smooth hops unique sharp hop flavor easy saturated well m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flip Ale</td>\n",
       "      <td>Dogfish Head Craft Brewery</td>\n",
       "      <td>Old Ale</td>\n",
       "      <td>4.08</td>\n",
       "      <td>on tap at dfh rehoboth... collab with eatily... cardamom and red wine must. golden orange. .no head. typical dfh yeast aroma. ..some spice and maybe a belgian influence. sweet spicy and somewhat fruity.. not much ol...</td>\n",
       "      <td>tap dfh rehoboth collab eatily cardamom red wine must golden orange head typical dfh yeast aroma spice maybe belgian influence sweet spicy somewhat fruity much old ale characteristic light still tasty cardamom add ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Almond Marzen Project - Beer Camp #26</td>\n",
       "      <td>Sierra Nevada Brewing Co.</td>\n",
       "      <td>Märzen / Oktoberfest</td>\n",
       "      <td>3.78</td>\n",
       "      <td>nice auburn impressions, tons of clarity, solid inch of off white head.   aroma was a little bit sweet and nutty. taste gave a little more sweetness, stayed away from hops and bitterness, relatively light bodied.  no...</td>\n",
       "      <td>nice auburn impressions tons clarity solid inch white head aroma little bit sweet nutty taste gave little sweetness stayed away hops bitterness relatively light bodied nothing almond came obvious kind fancied oktober...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name                     brewery  \\\n",
       "index                                                                          \n",
       "0                                   Big Rock Ale            Big Rock Brewery   \n",
       "1                                       Flip Ale  Dogfish Head Craft Brewery   \n",
       "2      The Almond Marzen Project - Beer Camp #26   Sierra Nevada Brewing Co.   \n",
       "\n",
       "                      style  rating  \\\n",
       "index                                 \n",
       "0              Scottish Ale    3.90   \n",
       "1                   Old Ale    4.08   \n",
       "2      Märzen / Oktoberfest    3.78   \n",
       "\n",
       "                                                                                                                                                                                                                            review  \\\n",
       "index                                                                                                                                                                                                                                \n",
       "0      smell  soft hop aroma with significant malt scents. this one smells very creamy. taste  and creamy it is. the traditional irish flavors come out at the tongue. this is creamy, not like a cream ale, but close. the m...   \n",
       "1       on tap at dfh rehoboth... collab with eatily... cardamom and red wine must. golden orange. .no head. typical dfh yeast aroma. ..some spice and maybe a belgian influence. sweet spicy and somewhat fruity.. not much ol...   \n",
       "2      nice auburn impressions, tons of clarity, solid inch of off white head.   aroma was a little bit sweet and nutty. taste gave a little more sweetness, stayed away from hops and bitterness, relatively light bodied.  no...   \n",
       "\n",
       "                                                                                                                                                                                                                      clean_review  \n",
       "index                                                                                                                                                                                                                               \n",
       "0      smell soft hop aroma significant malt scents one smells creamy taste creamy traditional irish flavors come tongue creamy like cream ale close malt big buttery smooth hops unique sharp hop flavor easy saturated well m...  \n",
       "1      tap dfh rehoboth collab eatily cardamom red wine must golden orange head typical dfh yeast aroma spice maybe belgian influence sweet spicy somewhat fruity much old ale characteristic light still tasty cardamom add ni...  \n",
       "2      nice auburn impressions tons clarity solid inch white head aroma little bit sweet nutty taste gave little sweetness stayed away hops bitterness relatively light bodied nothing almond came obvious kind fancied oktober...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA PREP\n",
    "print('df original length',len(df))\n",
    "# drop all reviews with < 20 characters\n",
    "df = df[df['review'].map(len) > 20]\n",
    "print('length without short reviews',len(df))\n",
    "\n",
    "# remove uncommon styles (in EDA, I found 13 styles with fewer than 60 reviews)\n",
    "#uncommon = [ 'American Dark Wheat Ale','Bière de Champagne / Bière Brut', 'Black & Tan', \n",
    "#            'Eisbock', 'Faro', 'Gueuze', 'Happoshu', 'Japanese Rice Lager', 'Kristalweizen',\n",
    "#            'Kvass', 'Lambic - Unblended','Roggenbier', 'Sahti' ]   \n",
    "labels = df.groupby(['style']).size() \n",
    "uncommon = labels[labels<130]\n",
    "df = df.loc[~df['style'].isin(uncommon.index)]\n",
    "print('length without uncommon styles',len(df))\n",
    "\n",
    "# reset dataframe index for the shortened dataframe\n",
    "df['index'] = np.arange(len(df))\n",
    "df = df.set_index('index')\n",
    "\n",
    "# Change review to a string of words.  remove non-letters, make lower case, split into words.  \n",
    "# Remove stopwords (common words.)  Join back together into a long string of words.  \n",
    "def review_to_words(review):\n",
    "    letters_only = re.sub('[^a-zA-Z]',' ', review)\n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words('english'))  \n",
    "    good_words = [w for w in words if not w in stops]\n",
    "    return(' '.join(good_words))\n",
    "\n",
    "# clean the reviews\n",
    "df['clean_review'] = df['review'].apply(review_to_words)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47555"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.name.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ADDITIONAL FEATURE ENGINEERING\n",
    "# review length\n",
    "df['review_length'] = df['review'].apply(len)\n",
    "\n",
    "# average word length\n",
    "def avg_word_len(words):\n",
    "    separate_words = words.split()\n",
    "    count_words = (len(separate_words))    # number of words\n",
    "    if count_words> 0:\n",
    "        characters = len(words)  # length of text\n",
    "        avg = (characters - count_words+1)/count_words\n",
    "    else:\n",
    "        avg = 5.65  # this is the mean of 49000 reviews    \n",
    "    return avg   \n",
    "\n",
    "df['avg_word_length'] = df['clean_review'].apply(avg_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 1912.8401219640416\n",
      "max:  22085\n",
      "min:  21\n",
      "\n",
      "mean: 5.6837926135651\n",
      "max:  11.0\n",
      "min:  3.0\n"
     ]
    }
   ],
   "source": [
    "print('mean:',df['review_length'].mean())\n",
    "print('max: ',df['review_length'].max())\n",
    "print('min: ',df['review_length'].min())\n",
    "print('')\n",
    "print('mean:',df['avg_word_length'].mean())\n",
    "print('max: ',df['avg_word_length'].max())\n",
    "print('min: ',df['avg_word_length'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of styles used: 57\n",
      "\n",
      "Index(['Altbier', 'American Amber / Red Ale', 'American Black Ale',\n",
      "       'American Blonde Ale', 'American Double / Imperial IPA',\n",
      "       'American Lager', 'American Pale Wheat Ale', 'American Strong Ale',\n",
      "       'American Wild Ale', 'Barleywine', 'Belgian Dark Ale',\n",
      "       'Belgian Strong Dark Ale', 'Belgian Strong Pale Ale',\n",
      "       'Berliner Weissbier', 'Bitter', 'Bock', 'Brown Ale', 'Cream Ale',\n",
      "       'Czech Pilsener', 'Doppelbock', 'Dubbel', 'Dunkelweizen',\n",
      "       'Euro Dark Lager', 'Euro Pale Lager', 'Farm Ale',\n",
      "       'Fruit / Vegetable Beer', 'German Pilsener', 'Gose', 'Hefeweizen',\n",
      "       'Herbed / Spiced Beer', 'IPA', 'Imperial Stout', 'Irish Dry Stout',\n",
      "       'Irish Red Ale', 'Kellerbier / Zwickelbier', 'Kölsch', 'Lager',\n",
      "       'Lambic - Fruit', 'Light Lager', 'Maibock / Helles Bock',\n",
      "       'Munich Dunkel Lager', 'Munich Helles Lager', 'Märzen / Oktoberfest',\n",
      "       'Old Ale', 'Pale Ale', 'Porter', 'Pumpkin Ale', 'Quadrupel (Quad)',\n",
      "       'Russian Imperial Stout', 'Rye Beer', 'Schwarzbier', 'Scottish Ale',\n",
      "       'Smoked Beer', 'Stout', 'Tripel', 'Winter Warmer', 'Witbier'],\n",
      "      dtype='object', name='style')\n"
     ]
    }
   ],
   "source": [
    "styles = df.groupby(['style']).size() \n",
    "print('Number of styles used:', len(styles))\n",
    "print('')\n",
    "print(styles.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMBINE SIMILAR STYLES OF BEER.  \n",
    "\n",
    "df['style'].replace('Saison / Farmhouse Ale', 'Farm Ale', inplace=True)\n",
    "df['style'].replace('Bière de Garde', 'Farm Ale', inplace=True)\n",
    "df['style'].replace('American IPA', 'IPA', inplace=True)\n",
    "df['style'].replace('English India Pale Ale (IPA)', 'IPA', inplace=True)\n",
    "df['style'].replace('Belgian IPA', 'IPA', inplace=True)\n",
    "df['style'].replace('Scotch Ale / Wee Heavy', 'Scottish Ale', inplace=True)\n",
    "df['style'].replace('American Pale Ale (APA)', 'Pale Ale', inplace=True)\n",
    "df['style'].replace('English Pale Ale', 'Pale Ale', inplace=True)\n",
    "df['style'].replace('Belgian Pale Ale', 'Pale Ale', inplace=True)\n",
    "df['style'].replace('American Brown Ale', 'Brown Ale', inplace=True)\n",
    "df['style'].replace('English Brown Ale', 'Brown Ale', inplace=True)\n",
    "df['style'].replace('English Dark Mild Ale', 'Brown Ale', inplace=True)\n",
    "df['style'].replace('American Stout', 'Stout', inplace=True)\n",
    "df['style'].replace('English Stout', 'Stout', inplace=True)\n",
    "df['style'].replace('Milk / Sweet Stout', 'Stout', inplace=True)\n",
    "df['style'].replace('Oatmeal Stout', 'Stout', inplace=True)\n",
    "df['style'].replace('Oatmeal Stout', 'Stout', inplace=True)\n",
    "df['style'].replace('American Double / Imperial Stout', 'Imperial Stout', inplace=True)\n",
    "df['style'].replace('Russian Imperial', 'Imperial Stout', inplace=True)\n",
    "df['style'].replace('American Porter', 'Porter', inplace=True)\n",
    "df['style'].replace('Baltic Porter', 'Porter', inplace=True)\n",
    "df['style'].replace('English Porter', 'Porter', inplace=True)\n",
    "df['style'].replace('American Amber / Red Lager', 'Lager', inplace=True)\n",
    "df['style'].replace('Vienna Lager', 'Lager', inplace=True)\n",
    "df['style'].replace('German Pilsener', 'Lager', inplace=True)\n",
    "df['style'].replace('Munich Helles Lager', 'Lager', inplace=True)\n",
    "df['style'].replace('American Adjunct Lager', 'American Lager', inplace=True)\n",
    "df['style'].replace('American Pale Lager', 'American Lager', inplace=True)\n",
    "df['style'].replace('American Barleywine', 'Barleywine', inplace=True)\n",
    "df['style'].replace('English Barleywine', 'Barleywine', inplace=True)\n",
    "df['style'].replace('English Bitter', 'Bitter', inplace=True)\n",
    "df['style'].replace('Extra Special / Strong Bitter (ESB)', 'Bitter', inplace=True)\n",
    "df['style'].replace('American Pale Wheat Ale', 'Wheat', inplace=True)\n",
    "df['style'].replace('Witbier', 'Wheat', inplace=True)\n",
    "#df['style'].replace('Witbier', 'Wheat', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of styles used: 54\n",
      "\n",
      "Index(['Altbier', 'American Amber / Red Ale', 'American Black Ale',\n",
      "       'American Blonde Ale', 'American Double / Imperial IPA',\n",
      "       'American Lager', 'American Strong Ale', 'American Wild Ale',\n",
      "       'Barleywine', 'Belgian Dark Ale', 'Belgian Strong Dark Ale',\n",
      "       'Belgian Strong Pale Ale', 'Berliner Weissbier', 'Bitter', 'Bock',\n",
      "       'Brown Ale', 'Cream Ale', 'Czech Pilsener', 'Doppelbock', 'Dubbel',\n",
      "       'Dunkelweizen', 'Euro Dark Lager', 'Euro Pale Lager', 'Farm Ale',\n",
      "       'Fruit / Vegetable Beer', 'Gose', 'Hefeweizen', 'Herbed / Spiced Beer',\n",
      "       'IPA', 'Imperial Stout', 'Irish Dry Stout', 'Irish Red Ale',\n",
      "       'Kellerbier / Zwickelbier', 'Kölsch', 'Lager', 'Lambic - Fruit',\n",
      "       'Light Lager', 'Maibock / Helles Bock', 'Munich Dunkel Lager',\n",
      "       'Märzen / Oktoberfest', 'Old Ale', 'Pale Ale', 'Porter', 'Pumpkin Ale',\n",
      "       'Quadrupel (Quad)', 'Russian Imperial Stout', 'Rye Beer', 'Schwarzbier',\n",
      "       'Scottish Ale', 'Smoked Beer', 'Stout', 'Tripel', 'Wheat',\n",
      "       'Winter Warmer'],\n",
      "      dtype='object', name='style')\n"
     ]
    }
   ],
   "source": [
    "styles = df.groupby(['style']).size() \n",
    "print('Number of styles used:', len(styles))\n",
    "print('')\n",
    "print(styles.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.841269841269841"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_word_len(df['clean_review'][12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 33288 y_train: 33288\n",
      "X_test: 14267 y_test: 14267\n",
      "X_train shape: (33288,)\n",
      "y_train shape: (33288,)\n"
     ]
    }
   ],
   "source": [
    "# PREDICT STYLE FROM REVIEWS\n",
    "# split into train and test data\n",
    "X = df['clean_review'].values\n",
    "y = df['style'].values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3, random_state=22)\n",
    "print('X_train:',len(X_train), 'y_train:',len(y_train))\n",
    "print('X_test:', len(X_test), 'y_test:', len(y_test))\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('y_train shape:',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Stout', 'American Amber / Red Ale', 'American Amber / Red Ale',\n",
       "       'Russian Imperial Stout', 'American Lager', 'Pale Ale',\n",
       "       'Barleywine', 'Pale Ale', 'American Double / Imperial IPA',\n",
       "       'American Amber / Red Ale', 'Farm Ale', 'IPA', 'IPA',\n",
       "       'American Double / Imperial IPA', 'Light Lager', 'Hefeweizen',\n",
       "       'Porter', 'American Wild Ale', 'Pale Ale', 'American Blonde Ale'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smell \\x96 soft hop aroma with significant malt scents. this one smells very creamy. taste \\x96 and creamy it is. the traditional irish flavors come out at the tongue. this is creamy, not like a cream ale, but close. the malt is big, buttery, and very smooth. the hops are very unique. this is not a sharp hop flavor. this is an easy, saturated, well-mixed blend that plays a complimenting second fiddle to the malt base. no sweetness. the finish is nutty and big. this ale changes personalities at the end. mouthfeel \\x96 lightly carbonated and exceptionally smooth and creamy. drinkability \\x96 very creamy. i know that i\\x92m repeating myself, but this ale is creamy like peanut butter. it\\x92s actually kind of nutty to boot. creamy. '"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smell soft hop aroma significant malt scents one smells creamy taste creamy traditional irish flavors come tongue creamy like cream ale close malt big buttery smooth hops unique sharp hop flavor easy saturated well mixed blend plays complimenting second fiddle malt base sweetness finish nutty big ale changes personalities end mouthfeel lightly carbonated exceptionally smooth creamy drinkability creamy know repeating ale creamy like peanut butter actually kind nutty boot creamy'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 styles excluded:\n",
      "Index(['American Dark Wheat Ale', 'American Double / Imperial Pilsner',\n",
      "       'American Malt Liquor', 'Bière de Champagne / Bière Brut',\n",
      "       'Black & Tan', 'Braggot', 'California Common / Steam Beer',\n",
      "       'Chile Beer', 'Dortmunder / Export Lager', 'Eisbock',\n",
      "       'English Pale Mild Ale', 'English Strong Ale', 'Euro Strong Lager',\n",
      "       'Faro', 'Flanders Oud Bruin', 'Flanders Red Ale',\n",
      "       'Foreign / Export Stout', 'Gueuze', 'Happoshu', 'Japanese Rice Lager',\n",
      "       'Kristalweizen', 'Kvass', 'Lambic - Unblended', 'Low Alcohol Beer',\n",
      "       'Rauchbier', 'Roggenbier', 'Sahti',\n",
      "       'Scottish Gruit / Ancient Herbed Ale', 'Weizenbock', 'Wheatwine'],\n",
      "      dtype='object', name='style')\n"
     ]
    }
   ],
   "source": [
    "print(len(uncommon), 'styles excluded:')\n",
    "print(uncommon.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 styles included:\n",
      "Index(['Altbier', 'American Adjunct Lager', 'American Amber / Red Ale',\n",
      "       'American Amber / Red Lager', 'American Barleywine',\n",
      "       'American Black Ale', 'American Blonde Ale', 'American Brown Ale',\n",
      "       'American Double / Imperial IPA', 'American Double / Imperial Stout',\n",
      "       'American IPA', 'American Pale Ale (APA)', 'American Pale Lager',\n",
      "       'American Pale Wheat Ale', 'American Porter', 'American Stout',\n",
      "       'American Strong Ale', 'American Wild Ale', 'Baltic Porter',\n",
      "       'Belgian Dark Ale', 'Belgian IPA', 'Belgian Pale Ale',\n",
      "       'Belgian Strong Dark Ale', 'Belgian Strong Pale Ale',\n",
      "       'Berliner Weissbier', 'Bière de Garde', 'Bock', 'Cream Ale',\n",
      "       'Czech Pilsener', 'Doppelbock', 'Dubbel', 'Dunkelweizen',\n",
      "       'English Barleywine', 'English Bitter', 'English Brown Ale',\n",
      "       'English Dark Mild Ale', 'English India Pale Ale (IPA)',\n",
      "       'English Pale Ale', 'English Porter', 'English Stout',\n",
      "       'Euro Dark Lager', 'Euro Pale Lager',\n",
      "       'Extra Special / Strong Bitter (ESB)', 'Fruit / Vegetable Beer',\n",
      "       'German Pilsener', 'Gose', 'Hefeweizen', 'Herbed / Spiced Beer',\n",
      "       'Irish Dry Stout', 'Irish Red Ale', 'Kellerbier / Zwickelbier',\n",
      "       'Kölsch', 'Lambic - Fruit', 'Light Lager', 'Maibock / Helles Bock',\n",
      "       'Milk / Sweet Stout', 'Munich Dunkel Lager', 'Munich Helles Lager',\n",
      "       'Märzen / Oktoberfest', 'Oatmeal Stout', 'Old Ale', 'Pumpkin Ale',\n",
      "       'Quadrupel (Quad)', 'Russian Imperial Stout', 'Rye Beer',\n",
      "       'Saison / Farmhouse Ale', 'Schwarzbier', 'Scotch Ale / Wee Heavy',\n",
      "       'Scottish Ale', 'Smoked Beer', 'Tripel', 'Vienna Lager',\n",
      "       'Winter Warmer', 'Witbier'],\n",
      "      dtype='object', name='style')\n"
     ]
    }
   ],
   "source": [
    "beer_styles = df.groupby(['style']).size() \n",
    "print(len(beer_styles), 'styles included:')\n",
    "print(beer_styles.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorize the train data, fit and transform into feature vectors\n",
    "vectorizer = CountVectorizer(analyzer='word', min_df=7)\n",
    "train_data_features = vectorizer.fit_transform(X_train)\n",
    "# arrays are easy to work with, so:\n",
    "#train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 100 words: ['aa', 'aal', 'aals', 'aaron', 'ab', 'aba', 'aback', 'abandon', 'abandoned', 'abarwithnoname', 'abate', 'abates', 'abbaye', 'abbey', 'abbot', 'abbreviated', 'abby', 'abc', 'abd', 'abe', 'abetted', 'abetting', 'abilities', 'ability', 'abit', 'abita', 'able', 'ably', 'abner', 'abnormal', 'abnormally', 'aboard', 'abomination', 'abound', 'abounding', 'abounds', 'abovementioned', 'abrasion', 'abrasive', 'abrasively', 'abrasiveness', 'abraxas', 'abroad', 'abrupt', 'abruptly', 'abs', 'absence', 'absent', 'absinthe', 'absolute', 'absolutely', 'absolutly', 'absorb', 'absorbed', 'absorbing', 'absorbs', 'abstract', 'absurd', 'absurdly', 'abt', 'abundance', 'abundant', 'abundantly', 'abuse', 'abused', 'abv', 'abvs', 'abw', 'abysmal', 'abyss', 'ac', 'acacia', 'academy', 'acbf', 'accent', 'accented', 'accenting', 'accents', 'accentuate', 'accentuated', 'accentuates', 'accentuating', 'accept', 'acceptable', 'accepted', 'access', 'accessibility', 'accessible', 'accident', 'accidental', 'accidentally', 'acclaimed', 'acclimate', 'acclimated', 'acclimates', 'accolades', 'accommodate', 'accompanied', 'accompanies', 'accompaniment']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print('first 100 words:', vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26388790098869053"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NAIVE BAYES PREDICTOR\n",
    "\n",
    "text_clf= Pipeline([('vect', CountVectorizer(min_df=7)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf',MultinomialNB()) ])\n",
    "# first pass, .1195,  after word cleaning .2076,  after combining styles .2639\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46200000000000002"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RANDOM FOREST \n",
    "#first pass 0.45, after cleaning 0.426, after combined styles 0.462\n",
    "\n",
    "X_train2 = X_train[:5000]\n",
    "y_train2 = y_train[:5000]\n",
    "X_test2 = X_test[10000:10500]\n",
    "y_test2 = y_test[10000:10500]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "text_clf= Pipeline([('vect', CountVectorizer(min_df=5)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('forest',RFC(n_estimators=300)) ])\n",
    "text_clf = text_clf.fit(X_train2, y_train2)\n",
    "predicted = text_clf.predict(X_test2)\n",
    "np.mean(predicted == y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62180809445906537"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "#after cleaning, 0.575,  after combined styles 0.6218\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# vectorize the train data, fit and transform into feature vectors\n",
    "text_clf= Pipeline([('vect', CountVectorizer(min_df=5)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf',LogisticRegression()) ])\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "\n",
    "#scores = cross_val_score(LogisticRegression(), train_data_features, y_train, cv=5)\n",
    "#print('mean cross-val accuracy: {:.2f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "#this is quite slow.  don't run it until I can improve speed (min_df=5 is a start)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.001,0.01, 0.1, 1,10]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print('best cross-val score: {:.2f}'.format(grid.gest_score_))\n",
    "print('best params:', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KMEANS COULD BE USED TO GROUP STYLES TOGETHER.  (use this before consolidating)\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# DATA PREP\n",
    "group_df = df_copy\n",
    "# drop all reviews with < 20 characters\n",
    "group_df = group_df[group_df['review'].map(len) > 20]\n",
    "\n",
    "# Change review to a string of words.  remove non-letters, make lower case, split into words.  \n",
    "# Remove stopwords (common words.)  Join back together into a long string of words.  \n",
    "def review_to_words(review):\n",
    "    letters_only = re.sub('[^a-zA-Z]',' ', review)\n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words('english'))  \n",
    "    good_words = [w for w in words if not w in stops]\n",
    "    return(' '.join(good_words))\n",
    "\n",
    "# clean the reviews\n",
    "df['clean_group_df'] = df['review'].apply(review_to_words)\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', min_df=7)\n",
    "train_data_features = vectorizer.fit_transform(df.clean_group_df)\n",
    "\n",
    "# Initialize the model with 2 parameters -- number of clusters and random state.\n",
    "kmeans_model = KMeans(n_clusters=20, random_state=22)\n",
    "# Get only the styles\n",
    "styles = group_df.style\n",
    "variables = train_data_features\n",
    "# Fit the model using the good columns.\n",
    "kmeans_model.fit(variables)\n",
    "# Get the cluster assignments.\n",
    "labels = kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 18.  18.   7. ...,   0.  15.   3.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-47c4b509effb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpca_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Fit the PCA model on the numeric columns from earlier.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplot_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Make a scatter plot of each game, shaded according to cluster assignment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 370\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 18.  18.   7. ...,   0.  15.   3.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Import the PCA model.\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA model.\n",
    "pca_2 = PCA(2)\n",
    "# Fit the PCA model on the numeric columns from earlier.\n",
    "plot_columns = pca_2.fit_transform(labels)\n",
    "# Make a scatter plot of each game, shaded according to cluster assignment.\n",
    "plt.scatter(x=plot_columns[:,0], y=plot_columns[:,1], c=labels)\n",
    "# Show the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46861, 8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_reviews = len(X_test)\n",
    "clean_test_reviews = []\n",
    "for b in range(0, num_reviews):\n",
    "    clean_test_reviews.append(review_to_words(X_test[b]))\n",
    "    \n",
    "test_data_features = vectorizer.transform(X_test)\n",
    "test_data_features = test_data_features.toarray()\n",
    "result = forest.predict(test_data_features)\n",
    "output = pd.DataFrame(data = {'id':test['id'], 'style':result})\n",
    "output_to_csv('BagOfWords_model.csv', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426\n",
      "{'nice': 220, 'auburn': 31, 'impressions': 163, 'tons': 350, 'of': 232, 'clarity': 72, 'solid': 308, 'inch': 165, 'off': 233, 'white': 372, 'head': 144, 'aroma': 28, 'was': 364, 'little': 192, 'bit': 45, 'sweet': 327, 'and': 21, 'nutty': 229, 'taste': 331, 'gave': 125, 'more': 213, 'sweetness': 328, 'stayed': 316, 'away': 33, 'from': 121, 'hops': 153, 'bitterness': 47, 'relatively': 278, 'light': 188, 'bodied': 50, 'nothing': 226, 'almond': 11, 'came': 61, 'out': 240, 'it': 171, 'that': 335, 'obvious': 230, 'kind': 177, 'fancied': 112, 'up': 358, 'oktoberfest': 234, 'while': 371, 'good': 132, \n"
     ]
    }
   ],
   "source": [
    "print(len(str(vectorizer.vocabulary_)))\n",
    "print(str(vectorizer.vocabulary_)[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0 0 0 0 1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 1 5 0 0 0 0 0 1 1 0 2 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 2 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      "  0 0 0 2 0 0 0 2 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      "  0 0 2 7 0 0 0 0 0 6 0 0 0 0 2 0 0 0 0 0 1 0 0 0 1 0 0 0 0 4 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X2 = [df['review'][0]] \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X)\n",
    "vector = vectorizer.transform(X2)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426\n",
      "{'nice': 220, 'auburn': 31, 'impressions': 163, 'tons': 350, 'of': 232, 'clarity': 72, 'solid': 308, 'inch': 165, 'off': 233, 'white': 372, 'head': 144, 'aroma': 28, 'was': 364, 'little': 192, 'bit': 45, 'sweet': 327, 'and': 21, 'nutty': 229, 'taste': 331, 'gave': 125, 'more': 213, 'sweetness': 328, 'stayed': 316, 'away': 33, 'from': 121, 'hops': 153, 'bitterness': 47, 'relatively': 278, 'light': 188, 'bodied': 50, 'nothing': 226, 'almond': 11, 'came': 61, 'out': 240, 'it': 171, 'that': 335, 'obvious': 230, 'kind': 177, 'fancied': 112, 'up': 358, 'oktoberfest': 234, 'while': 371, 'good': 132, \n"
     ]
    }
   ],
   "source": [
    "print(len(str(vectorizer.vocabulary_)))\n",
    "print(str(vectorizer.vocabulary_)[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 1 5 0 0 0 0 0 1 1 0 2 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 2 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      "  0 0 0 2 0 0 0 2 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      "  0 0 2 7 0 0 0 0 0 6 0 0 0 0 2 0 0 0 0 0 1 0 0 0 1 0 0 0 0 4 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vector = vectorizer.transform(X2)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426\n",
      "{'nice': 220, 'auburn': 31, 'impressions': 163, 'tons': 350, 'of': 232, 'clarity': 72, 'solid': 308, 'inch': 165, 'off': 233, 'white': 372, 'head': 144, 'aroma': 28, 'was': 364, 'little': 192, 'bit': 45, 'sweet': 327, 'and': 21, 'nutty': 229, 'taste': 331, 'gave': 125, 'more': 213, 'sweetness': 328, 'stayed': 316, 'away': 33, 'from': 121, 'hops': 153, 'bitterness': 47, 'relatively': 278, 'light': 188, 'bodied': 50, 'nothing': 226, 'almond': 11, 'came': 61, 'out': 240, 'it': 171, 'that': 335, 'obvious': 230, 'kind': 177, 'fancied': 112, 'up': 358, 'oktoberfest': 234, 'while': 371, 'good': 132, \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(X)\n",
    "# summarize\n",
    "print(len(str(vectorizer.vocabulary_)))\n",
    "print(str(vectorizer.vocabulary_)[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.20350706  7.90825515  7.90825515 ...,  7.50279005  7.90825515\n",
      "  7.90825515]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n",
      "[[ 0.01357063  0.01357063  0.0407119   0.01357063  0.02714126  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.02714126  0.05428253\n",
      "   0.13570632  0.01357063  0.01357063  0.01357063  0.08142379  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.36640707  0.01357063  0.01357063\n",
      "   0.02714126  0.01357063  0.01357063  0.0407119   0.01357063  0.01357063\n",
      "   0.14927696  0.01357063  0.01357063  0.01357063  0.02714126  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.05428253  0.13570632  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.0407119   0.01357063  0.01357063\n",
      "   0.01357063  0.0407119   0.02714126  0.0407119   0.01357063  0.10856506\n",
      "   0.02714126  0.02714126  0.02714126  0.01357063  0.01357063  0.01357063\n",
      "   0.0407119   0.02714126  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.02714126  0.06785316  0.0407119   0.01357063  0.0407119   0.02714126\n",
      "   0.0407119   0.01357063  0.01357063  0.05428253  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.02714126  0.02714126  0.01357063  0.02714126  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.09499443  0.01357063  0.01357063\n",
      "   0.01357063  0.02714126  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.0407119   0.01357063  0.02714126  0.01357063  0.01357063\n",
      "   0.02714126  0.01357063  0.02714126  0.01357063  0.01357063  0.08142379\n",
      "   0.01357063  0.01357063  0.01357063  0.05428253  0.08142379  0.01357063\n",
      "   0.08142379  0.01357063  0.01357063  0.01357063  0.02714126  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.0407119   0.01357063  0.05428253\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.02714126  0.01357063  0.17641822  0.01357063  0.01357063  0.01357063\n",
      "   0.05428253  0.01357063  0.14927696  0.18998885  0.02714126  0.01357063\n",
      "   0.01357063  0.06785316  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.08142379  0.02714126  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.01357063  0.09499443  0.01357063  0.05428253  0.01357063\n",
      "   0.0407119   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.06785316  0.02714126  0.01357063  0.06785316  0.01357063\n",
      "   0.01357063  0.0407119   0.05428253  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.06785316  0.01357063  0.01357063\n",
      "   0.02714126  0.01357063  0.05428253  0.0407119   0.08142379  0.09499443\n",
      "   0.01357063  0.01357063  0.05428253  0.05428253  0.05428253  0.01357063\n",
      "   0.02714126  0.06785316  0.01357063  0.01357063  0.25784201  0.0407119\n",
      "   0.05428253  0.0407119   0.05428253  0.0407119   0.01357063  0.01357063\n",
      "   0.08142379  0.01357063  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.0407119   0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.0407119   0.01357063  0.0407119   0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.02714126  0.01357063  0.01357063  0.06785316  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.05428253  0.01357063\n",
      "   0.05428253  0.01357063  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.02714126  0.01357063  0.0407119   0.01357063  0.02714126\n",
      "   0.01357063  0.01357063  0.01357063  0.02714126  0.01357063  0.01357063\n",
      "   0.02714126  0.02714126  0.01357063  0.02714126  0.01357063  0.01357063\n",
      "   0.01357063  0.0407119   0.01357063  0.02714126  0.0407119   0.0407119\n",
      "   0.01357063  0.08142379  0.01357063  0.01357063  0.01357063  0.08142379\n",
      "   0.36640707  0.01357063  0.01357063  0.02714126  0.02714126  0.01357063\n",
      "   0.27141265  0.01357063  0.01357063  0.01357063  0.01357063  0.20355949\n",
      "   0.05428253  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.02714126  0.08142379  0.01357063\n",
      "   0.01357063  0.02714126  0.10856506  0.01357063  0.16284759  0.01357063\n",
      "   0.02714126  0.02714126  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.0407119   0.01357063  0.21713012  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.02714126  0.01357063  0.02714126]]\n"
     ]
    }
   ],
   "source": [
    "# encode document\n",
    "vector = vectorizer.transform([X[0]])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'smell': 11165, 'soft': 11263, 'hop': 6090, 'aroma': 918, 'with': 13621, 'significant': 10951, 'malt': 7438, 'scents': 10579, 'this': 12373, 'one': 8499, 'smells': 11171, 'very': 13165, 'creamy': 3179, 'taste': 12183, 'and': 760, 'it': 6575, 'is': 6562, 'the': 12317, 'traditional': 12594, 'irish': 6546, 'flavors': 4964, 'come': 2790, 'out': 8606, 'at': 1005, 'tongue': 12522, 'not': 8299, 'like': 7146, 'cream': 3171, 'ale': 629, 'but': 2030, 'close': 2653, 'big': 1452, 'buttery': 2039, 'smooth': 11194, 'hops': 6116, 'are': 896, 'unique': 12939, 'sharp': 10812, 'flavor': 4957, 'an': 750, 'easy': 4133, 'saturated': 10524, 'well': 13435, 'mixed': 7865, 'blend': 1560, 'that': 12312, 'plays': 9177, 'complimenting': 2866, 'second': 10666, 'fiddle': 4818, 'to': 12482, 'base': 1222, 'no': 8248, 'sweetness': 12034, 'finish': 4878, 'nutty': 8357, 'changes': 2388, 'personalities': 9001, 'end': 4289, 'mouthfeel': 8004, 'lightly': 7135, 'carbonated': 2203, 'exceptionally': 4515, 'drinkability': 400\n",
      "236226\n"
     ]
    }
   ],
   "source": [
    "# vectorize with a list of reviews\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "X = df['review'][0:2000]\n",
    "\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(X)\n",
    "# summarize\n",
    "print(str(vectorizer.vocabulary_)[:1000])  # print a slice because this is very long\n",
    "print(len(str(vectorizer.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n",
      "[[ 0.07887912  0.01314652 -0.0657326   0.02629304 -0.0657326  -0.17090475\n",
      "  -0.01314652  0.         -0.28922343  0.01314652  0.10517215  0.01314652\n",
      "   0.28922343 -0.14461171 -0.01314652  0.01314652 -0.02629304 -0.10517215\n",
      "   0.21034431  0.          0.07887912  0.14461171 -0.07887912  0.02629304\n",
      "  -0.21034431  0.07887912 -0.14461171  0.14461171  0.01314652  0.\n",
      "   0.02629304 -0.03943956  0.24978387  0.14461171  0.07887912  0.15775823\n",
      "   0.07887912 -0.02629304  0.23663735  0.13146519 -0.22349083  0.19719779\n",
      "   0.         -0.03943956  0.07887912 -0.36810254  0.36810254 -0.07887912\n",
      "  -0.03943956  0.01314652]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "X = [df['review'][2]]  # start with a long review\n",
    "X2 = [df['review'][0]] # X2 is shorter\n",
    "\n",
    "# create the transform\n",
    "vectorizer = HashingVectorizer(n_features=50)\n",
    "# encode document\n",
    "vector = vectorizer.transform(X)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = df.groupby(['style']).size()\n",
    "styles = counts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Altbier', 'American Adjunct Lager', 'American Amber / Red Ale',\n",
       "       'American Amber / Red Lager', 'American Barleywine',\n",
       "       'American Black Ale', 'American Blonde Ale', 'American Brown Ale',\n",
       "       'American Dark Wheat Ale', 'American Double / Imperial IPA',\n",
       "       ...\n",
       "       'Scotch Ale / Wee Heavy', 'Scottish Ale',\n",
       "       'Scottish Gruit / Ancient Herbed Ale', 'Smoked Beer', 'Tripel',\n",
       "       'Vienna Lager', 'Weizenbock', 'Wheatwine', 'Winter Warmer', 'Witbier'],\n",
       "      dtype='object', name='style', length=104)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 33288 y_train: 33288\n",
      "X_test: 14267 y_test: 14267\n",
      "X_train shape: (33288,)\n",
      "y_train shape: (33288,)\n"
     ]
    }
   ],
   "source": [
    "# PREDICT RATING FROM REVIEWS\n",
    "# split into train and test data\n",
    "X = df['clean_review'].values\n",
    "y = df['rating'].values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3, random_state=22)\n",
    "print('X_train:',len(X_train), 'y_train:',len(y_train))\n",
    "print('X_test:', len(X_test), 'y_test:', len(y_test))\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('y_train shape:',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Linear Regression predictor\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "text_clf= Pipeline([('vect', CountVectorizer(min_df=7)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('regr', linear_model.LinearRegression()) ])\n",
    "\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "Python\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def balance_classes(xs, ys):\n",
    "\"\"\"Undersample xs, ys to balance classes.\"\"\"\n",
    "freqs = Counter(ys)\n",
    "\n",
    "# the least common class is the maximum number we want for all classes\n",
    "max_allowable = freqs.most_common()[-1][1]\n",
    "num_added = {clss: 0 for clss in freqs.keys()}\n",
    "new_ys = []\n",
    "new_xs = []\n",
    "for i, y in enumerate(ys):\n",
    "if num_added[y] < max_allowable:\n",
    "new_ys.append(y)\n",
    "new_xs.append(xs[i])\n",
    "num_added[y] += 1\n",
    "return new_xs, new_ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    " \n",
    "# initialise the SVM classifier\n",
    "classifier = LinearSVC()\n",
    " \n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([ 3.78,  3.16,  4.27, ...,  4.1 ,  4.01,  3.81]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-3cf36a377729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                    ('clf',MultinomialNB()) ])\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# first pass, .1195,  after word cleaning .2076,  after combining styles .2639\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtext_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mlabelbin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([ 3.78,  3.16,  4.27, ...,  4.1 ,  4.01,  3.81]),)"
     ]
    }
   ],
   "source": [
    "# Naive Bayes predictor\n",
    "\n",
    "text_clf= Pipeline([('vect', CountVectorizer(min_df=7)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf',MultinomialNB()) ])\n",
    "\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RANDOM FOREST \n",
    "\n",
    "X_train2 = X_train[:5000]\n",
    "y_train2 = y_train[:5000]\n",
    "X_test2 = X_test[10000:10500]\n",
    "y_test2 = y_test[10000:10500]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "text_clf= Pipeline([('vect', CountVectorizer(min_df=5)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('forest',RFC(n_estimators=300)) ])\n",
    "text_clf = text_clf.fit(X_train2, y_train2)\n",
    "predicted = text_clf.predict(X_test2)\n",
    "np.mean(predicted == y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-a0079b451ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtest_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstyle_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     cv_loss = np.mean(cross_val_score(classifier, X_train_word_features, \n\u001b[0m\u001b[1;32m     21\u001b[0m                                       train_target, cv=5, scoring='neg_log_loss'))\n\u001b[1;32m     22\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "# CALCULATE PREDICTION FOR ONE STYLE  -- doesn't work on my data\n",
    "# from kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments\n",
    "# ValueError: Found input variables with inconsistent numbers of samples: [32802, 3857]\n",
    "# when calling cross_val_score.  I reduced df length in \"train_target = y_train[y_train==...]\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "word_vect = TfidfVectorizer()\n",
    "word_vect.fit(X_train)\n",
    "X_train_word_features = word_vect.transform(X_train)\n",
    "test_features = word_vect.transform(X_test)\n",
    "\n",
    "style_names = ['American IPA','American Porter'] \n",
    "# ['American Pale Ale (APA)','Saison / Farmhouse Ale','American Double / Imperial IPA']\n",
    "losses = []\n",
    "auc = []\n",
    "for style_name in style_names:\n",
    "    #call the labels one at a time so we can run the classifier on them\n",
    "    train_target = y_train[y_train==style_name]\n",
    "    test_target = y_test[y_test==style_name]\n",
    "    classifier = LogisticRegression(solver='sag', C=10)\n",
    "    cv_loss = np.mean(cross_val_score(classifier, X_train_word_features, \n",
    "                                      train_target, cv=5, scoring='neg_log_loss'))\n",
    "    losses.append(cv_loss)\n",
    "    print('CV Log_loss score for class {} is {}'.format(style_name, cv_loss))\n",
    "    cv_score = np.mean(cross_val_score(classifier, X_train_word_features, \n",
    "                                       train_target, cv=5, scoring='accuracy'))\n",
    "    print('CV Accuracy score for class {} is {}'.format(style_name, cv_score))\n",
    "    \n",
    "    classifier.fit(X_train, train_target)\n",
    "    y_pred = classifier.predict(test_features)\n",
    "    y_pred_prob = classifier.predict_proba(test_features)[:, 1]\n",
    "    auc_score = metrics.roc_auc_score(test_target, y_pred_prob)\n",
    "    auc.append(auc_score)\n",
    "    print(\"CV ROC_AUC score {}\\n\".format(auc_score))\n",
    "    \n",
    "    print(confusion_matrix(test_target, y_pred))\n",
    "    print(classification_report(test_target, y_pred))\n",
    "\n",
    "print('Total average CV Log_loss score is {}'.format(np.mean(losses)))\n",
    "print('Total average CV ROC_AUC score is {}'.format(np.mean(auc)))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### start over here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prep the data\n",
    "df = df_copy\n",
    "df = df.drop(['name','brewery'], axis=1)\n",
    "# drop all reviews with < 15 characters\n",
    "df = df[df['review'].map(len) > 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49291\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_id = 0\n",
    "text = df.loc[t_id, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-a38df8ab5db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import summarize, keywords\n",
    "\n",
    "word_scores = keywords(text, words=5, scores=True, split=True, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
