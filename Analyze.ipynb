{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYZE\n",
    "the data\n",
    "\n",
    "This is a work in progress  \n",
    "\n",
    "Vectorize the data in beer.review  \n",
    "Diminish the importance of common words  \n",
    "Compare ML algorithms to use the review data to predict beer.style  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 80818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brewery</th>\n",
       "      <th>style</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Rock Ale</td>\n",
       "      <td>Big Rock Brewery</td>\n",
       "      <td>Scottish Ale</td>\n",
       "      <td>3.90</td>\n",
       "      <td>smell  soft hop aroma with significant malt scents. this one smells very creamy. taste  and creamy it is. the traditional irish flavors come out at the tongue. this is creamy, not like a cream ale, but close. the malt is big, buttery, and very smooth. the hops are very unique. this is not a sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flip Ale</td>\n",
       "      <td>Dogfish Head Craft Brewery</td>\n",
       "      <td>Old Ale</td>\n",
       "      <td>4.08</td>\n",
       "      <td>on tap at dfh rehoboth... collab with eatily... cardamom and red wine must. golden orange. .no head. typical dfh yeast aroma. ..some spice and maybe a belgian influence. sweet spicy and somewhat fruity.. not much old ale characteristic. too light for that. its still tasty. the cardamom does add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Almond Marzen Project - Beer Camp #26</td>\n",
       "      <td>Sierra Nevada Brewing Co.</td>\n",
       "      <td>Märzen / Oktoberfest</td>\n",
       "      <td>3.78</td>\n",
       "      <td>nice auburn impressions, tons of clarity, solid inch of off white head.   aroma was a little bit sweet and nutty. taste gave a little more sweetness, stayed away from hops and bitterness, relatively light bodied.  nothing almond came out of it that was obvious.  kind of a fancied up oktoberfest ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        name                     brewery  \\\n",
       "0                               Big Rock Ale            Big Rock Brewery   \n",
       "1                                   Flip Ale  Dogfish Head Craft Brewery   \n",
       "2  The Almond Marzen Project - Beer Camp #26   Sierra Nevada Brewing Co.   \n",
       "\n",
       "                  style  rating  \\\n",
       "0          Scottish Ale    3.90   \n",
       "1               Old Ale    4.08   \n",
       "2  Märzen / Oktoberfest    3.78   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                        review  \n",
       "0  smell  soft hop aroma with significant malt scents. this one smells very creamy. taste  and creamy it is. the traditional irish flavors come out at the tongue. this is creamy, not like a cream ale, but close. the malt is big, buttery, and very smooth. the hops are very unique. this is not a sh...  \n",
       "1   on tap at dfh rehoboth... collab with eatily... cardamom and red wine must. golden orange. .no head. typical dfh yeast aroma. ..some spice and maybe a belgian influence. sweet spicy and somewhat fruity.. not much old ale characteristic. too light for that. its still tasty. the cardamom does add...  \n",
       "2  nice auburn impressions, tons of clarity, solid inch of off white head.   aroma was a little bit sweet and nutty. taste gave a little more sweetness, stayed away from hops and bitterness, relatively light bodied.  nothing almond came out of it that was obvious.  kind of a fancied up oktoberfest ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get modueles and get data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pd.set_option('max_colwidth', 300)\n",
    "df = pd.read_csv('beer.csv', header=0)\n",
    "df_copy = df  #save a copy of dataframe for reference. \n",
    "print('length',len(df))\n",
    "\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 49141\n",
      "length 46861\n",
      "total reviews: 46,861\n"
     ]
    }
   ],
   "source": [
    "#prep the data\n",
    "df = df.drop(['name','brewery'], axis=1)\n",
    "# drop all reviews with < 20 characters\n",
    "df = df[df['review'].map(len) > 20]\n",
    "print('length',len(df))\n",
    "\n",
    "# remove uncommon styles (in EDA, I found 13 styles with fewer than 60 reviews)\n",
    "#uncommon = [ 'American Dark Wheat Ale','Bière de Champagne / Bière Brut', 'Black & Tan', \n",
    "#            'Eisbock', 'Faro', 'Gueuze', 'Happoshu', 'Japanese Rice Lager', 'Kristalweizen',\n",
    "#            'Kvass', 'Lambic - Unblended','Roggenbier', 'Sahti' ]   \n",
    "labels = df.groupby(['style']).size() \n",
    "uncommon = labels[labels<150]\n",
    "df = df.loc[~df['style'].isin(uncommon.index)]\n",
    "print('length',len(df))\n",
    "\n",
    "X = df['review'].values\n",
    "y = df['style'].values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3, random_state=22)\n",
    "\n",
    "print('total reviews:', format(len(df), ',d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 32802 y_train: 32802\n",
      "X_test: 14059 y_test: 14059\n"
     ]
    }
   ],
   "source": [
    "print('X_train:',len(X_train), 'y_train:',len(y_train))\n",
    "print('X_test:', len(X_test), 'y_test:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of styles excluded: 30\n",
      "Index(['American Dark Wheat Ale', 'American Double / Imperial Pilsner',\n",
      "       'American Malt Liquor', 'Bière de Champagne / Bière Brut',\n",
      "       'Black & Tan', 'Braggot', 'California Common / Steam Beer',\n",
      "       'Chile Beer', 'Dortmunder / Export Lager', 'Eisbock',\n",
      "       'English Pale Mild Ale', 'English Strong Ale', 'Euro Strong Lager',\n",
      "       'Faro', 'Flanders Oud Bruin', 'Flanders Red Ale',\n",
      "       'Foreign / Export Stout', 'Gueuze', 'Happoshu', 'Japanese Rice Lager',\n",
      "       'Kristalweizen', 'Kvass', 'Lambic - Unblended', 'Low Alcohol Beer',\n",
      "       'Rauchbier', 'Roggenbier', 'Sahti',\n",
      "       'Scottish Gruit / Ancient Herbed Ale', 'Weizenbock', 'Wheatwine'],\n",
      "      dtype='object', name='style')\n"
     ]
    }
   ],
   "source": [
    "print('number of styles excluded:',len(uncommon))\n",
    "print(uncommon.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of styles included: 74\n",
      "Index(['Altbier', 'American Adjunct Lager', 'American Amber / Red Ale',\n",
      "       'American Amber / Red Lager', 'American Barleywine',\n",
      "       'American Black Ale', 'American Blonde Ale', 'American Brown Ale',\n",
      "       'American Double / Imperial IPA', 'American Double / Imperial Stout',\n",
      "       'American IPA', 'American Pale Ale (APA)', 'American Pale Lager',\n",
      "       'American Pale Wheat Ale', 'American Porter', 'American Stout',\n",
      "       'American Strong Ale', 'American Wild Ale', 'Baltic Porter',\n",
      "       'Belgian Dark Ale', 'Belgian IPA', 'Belgian Pale Ale',\n",
      "       'Belgian Strong Dark Ale', 'Belgian Strong Pale Ale',\n",
      "       'Berliner Weissbier', 'Bière de Garde', 'Bock', 'Cream Ale',\n",
      "       'Czech Pilsener', 'Doppelbock', 'Dubbel', 'Dunkelweizen',\n",
      "       'English Barleywine', 'English Bitter', 'English Brown Ale',\n",
      "       'English Dark Mild Ale', 'English India Pale Ale (IPA)',\n",
      "       'English Pale Ale', 'English Porter', 'English Stout',\n",
      "       'Euro Dark Lager', 'Euro Pale Lager',\n",
      "       'Extra Special / Strong Bitter (ESB)', 'Fruit / Vegetable Beer',\n",
      "       'German Pilsener', 'Gose', 'Hefeweizen', 'Herbed / Spiced Beer',\n",
      "       'Irish Dry Stout', 'Irish Red Ale', 'Kellerbier / Zwickelbier',\n",
      "       'Kölsch', 'Lambic - Fruit', 'Light Lager', 'Maibock / Helles Bock',\n",
      "       'Milk / Sweet Stout', 'Munich Dunkel Lager', 'Munich Helles Lager',\n",
      "       'Märzen / Oktoberfest', 'Oatmeal Stout', 'Old Ale', 'Pumpkin Ale',\n",
      "       'Quadrupel (Quad)', 'Russian Imperial Stout', 'Rye Beer',\n",
      "       'Saison / Farmhouse Ale', 'Schwarzbier', 'Scotch Ale / Wee Heavy',\n",
      "       'Scottish Ale', 'Smoked Beer', 'Tripel', 'Vienna Lager',\n",
      "       'Winter Warmer', 'Witbier'],\n",
      "      dtype='object', name='style')\n"
     ]
    }
   ],
   "source": [
    "beer_styles = df.groupby(['style']).size() \n",
    "print('number of styles included:',len(beer_styles))\n",
    "print(beer_styles.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change review to a string of words.  remove non-letters, make lower case, split into words.  \n",
    "# Remove stopwords (common words.)  Join back together into a long string of words.  \n",
    "\n",
    "def review_to_words(review):\n",
    "    letters_only = re.sub('[^a-zA-Z]',' ', review)\n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words('english'))  \n",
    "    good_words = [w for w in words if not w in stops]\n",
    "    return(' '.join(good_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean up train reviews\n",
    "num_reviews = len(X_train)\n",
    "clean_train_reviews = []\n",
    "for b in range(0, num_reviews):\n",
    "    clean_train_reviews.append(review_to_words(X_train[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean up test reviews\n",
    "num_reviews = len(X_test)\n",
    "clean_test_reviews = []\n",
    "for b in range(0, num_reviews):\n",
    "    clean_test_reviews.append(review_to_words(X_test[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one last pours gravity head brewed new holland brewing co restaurant pub chef cleetus friedman city provisions delicatessen named infamous marsha mallow nhb staff holiday party black head nice amount velvety lacing smoke chocolate malt huge malt smell takes sweet little sweet big chocolate malt espresso slight honey charred wood coats well want want stout thick little carbonation syrupy slight burn finish never glad tried nice example milk stout great mouthfeel overall way sweet took away complexity brew'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scuttlebutt ipa tap brewforia golden honey color tiny bit haze carbonation ok lacing nose soft fruit seems hop forward tongue malts work make nice backbone finishes grapefruit dryness mf soft light mouthfeel little drying sessionable notes beer definitely dry hop forward traditional west coast ipa jump conclusion english ipa either somewhere middle good way'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_reviews[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorize the train data, fit and transform into feature vectors\n",
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "# arrays are easy to work with, so:\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 120 words: ['aa', 'aaa', 'aaaaand', 'aaaack', 'aaaah', 'aaaahs', 'aaaand', 'aaah', 'aaahh', 'aaaiiyeeee', 'aachen', 'aachener', 'aack', 'aah', 'aahh', 'aaj', 'aal', 'aalborg', 'aalmost', 'aals', 'aan', 'aand', 'aantal', 'aapa', 'aapect', 'aara', 'aarde', 'aargh', 'aaron', 'aarrgh', 'aas', 'aasher', 'aass', 'aat', 'ab', 'aba', 'aback', 'abacus', 'abadia', 'abale', 'abandon', 'abandoned', 'abandoning', 'abandons', 'abarleywine', 'abarwithnoname', 'abas', 'abashed', 'abate', 'abated', 'abates', 'abating', 'abavarian', 'abb', 'abbaye', 'abbazia', 'abbbey', 'abbey', 'abbeys', 'abbot', 'abbott', 'abbreviate', 'abbreviated', 'abbreviation', 'abbundantly', 'abby', 'abbyaye', 'abbywinters', 'abc', 'abcense', 'abd', 'abdij', 'abdijbier', 'abdomen', 'abducting', 'abduction', 'abe', 'abeba', 'abeille', 'abeit', 'abel', 'aberdeen', 'aberlour', 'aberrartion', 'aberration', 'aberrations', 'abesentia', 'abet', 'abetted', 'abetter', 'abetters', 'abetting', 'abettor', 'abeyance', 'abf', 'abfod', 'abgb', 'abgef', 'abhoration', 'abi', 'abide', 'abides', 'abiding', 'abiet', 'abigail', 'abilene', 'abililty', 'abilities', 'ability', 'abinbev', 'abit', 'abita', 'abjectly', 'ablackshear', 'ablaze', 'ablazing', 'able', 'ableit', 'ables', 'ably']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print('first 120 words:', vocab[:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 aa\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-650b1b254f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "dist = np.sum(train_data_features, axis=1)\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print(count,tag)[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20755388007681913"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf= Pipeline([('vect', CountVectorizer(min_df=7)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf',MultinomialNB()) ])\n",
    "# first pass, .1195\n",
    "# after word cleaning, .2076\n",
    "text_clf = text_clf.fit(clean_train_reviews, y_train)\n",
    "predicted = text_clf.predict(clean_test_reviews)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11948877468217474"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train[:200]\n",
    "X_train2 = y_train[:200]\n",
    "\n",
    "print(X_train2.shape,X_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RANDOM FOREST \n",
    "\n",
    "clean_train_reviews2 = clean_train_reviews[:5000]\n",
    "y_train2 = y_train[:5000]\n",
    "clean_test_reviews2 = clean_test_reviews[10000:10500]\n",
    "y_test2 = y_test[10000:10500]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "text_clf= Pipeline([('vect', CountVectorizer(min_df=5)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('forest',RFC(n_estimators=300)) ])\n",
    "text_clf = text_clf.fit(clean_train_reviews2, y_train2)\n",
    "predicted = text_clf.predict(clean_test_reviews2)\n",
    "np.mean(predicted == y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57500533466107118"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# vectorize the train data, fit and transform into feature vectors\n",
    "text_clf= Pipeline([('vect', CountVectorizer(min_df=5)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf',LogisticRegression()) ])\n",
    "text_clf = text_clf.fit(clean_train_reviews, y_train)\n",
    "predicted = text_clf.predict(clean_test_reviews)\n",
    "np.mean(predicted == y_test)\n",
    "\n",
    "#scores = cross_val_score(LogisticRegression(), train_data_features, y_train, cv=5)\n",
    "#print('mean cross-val accuracy: {:.2f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is quite slow.  don't run it until I can improve speed (min_df=5 is a start)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.001,0.01, 0.1, 1,10]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(clean_train_reviews, y_train)\n",
    "print('best cross-val score: {:.2f}'.format(grid.gest_score_))\n",
    "print('best params:', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_reviews = len(X_test)\n",
    "clean_test_reviews = []\n",
    "for b in range(0, num_reviews):\n",
    "    clean_test_reviews.append(review_to_words(X_test[b]))\n",
    "    \n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "result = forest.predict(test_data_features)\n",
    "output = pd.DataFrame(data = {'id':test['id'], 'style':result})\n",
    "output_to_csv('BagOfWords_model.csv', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426\n",
      "{'nice': 220, 'auburn': 31, 'impressions': 163, 'tons': 350, 'of': 232, 'clarity': 72, 'solid': 308, 'inch': 165, 'off': 233, 'white': 372, 'head': 144, 'aroma': 28, 'was': 364, 'little': 192, 'bit': 45, 'sweet': 327, 'and': 21, 'nutty': 229, 'taste': 331, 'gave': 125, 'more': 213, 'sweetness': 328, 'stayed': 316, 'away': 33, 'from': 121, 'hops': 153, 'bitterness': 47, 'relatively': 278, 'light': 188, 'bodied': 50, 'nothing': 226, 'almond': 11, 'came': 61, 'out': 240, 'it': 171, 'that': 335, 'obvious': 230, 'kind': 177, 'fancied': 112, 'up': 358, 'oktoberfest': 234, 'while': 371, 'good': 132, \n"
     ]
    }
   ],
   "source": [
    "print(len(str(vectorizer.vocabulary_)))\n",
    "print(str(vectorizer.vocabulary_)[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0 0 0 0 1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 1 5 0 0 0 0 0 1 1 0 2 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 2 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      "  0 0 0 2 0 0 0 2 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      "  0 0 2 7 0 0 0 0 0 6 0 0 0 0 2 0 0 0 0 0 1 0 0 0 1 0 0 0 0 4 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X2 = [df['review'][0]] \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X)\n",
    "vector = vectorizer.transform(X2)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426\n",
      "{'nice': 220, 'auburn': 31, 'impressions': 163, 'tons': 350, 'of': 232, 'clarity': 72, 'solid': 308, 'inch': 165, 'off': 233, 'white': 372, 'head': 144, 'aroma': 28, 'was': 364, 'little': 192, 'bit': 45, 'sweet': 327, 'and': 21, 'nutty': 229, 'taste': 331, 'gave': 125, 'more': 213, 'sweetness': 328, 'stayed': 316, 'away': 33, 'from': 121, 'hops': 153, 'bitterness': 47, 'relatively': 278, 'light': 188, 'bodied': 50, 'nothing': 226, 'almond': 11, 'came': 61, 'out': 240, 'it': 171, 'that': 335, 'obvious': 230, 'kind': 177, 'fancied': 112, 'up': 358, 'oktoberfest': 234, 'while': 371, 'good': 132, \n"
     ]
    }
   ],
   "source": [
    "print(len(str(vectorizer.vocabulary_)))\n",
    "print(str(vectorizer.vocabulary_)[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 1 5 0 0 0 0 0 1 1 0 2 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 2 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      "  0 0 0 2 0 0 0 2 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      "  0 0 2 7 0 0 0 0 0 6 0 0 0 0 2 0 0 0 0 0 1 0 0 0 1 0 0 0 0 4 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vector = vectorizer.transform(X2)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426\n",
      "{'nice': 220, 'auburn': 31, 'impressions': 163, 'tons': 350, 'of': 232, 'clarity': 72, 'solid': 308, 'inch': 165, 'off': 233, 'white': 372, 'head': 144, 'aroma': 28, 'was': 364, 'little': 192, 'bit': 45, 'sweet': 327, 'and': 21, 'nutty': 229, 'taste': 331, 'gave': 125, 'more': 213, 'sweetness': 328, 'stayed': 316, 'away': 33, 'from': 121, 'hops': 153, 'bitterness': 47, 'relatively': 278, 'light': 188, 'bodied': 50, 'nothing': 226, 'almond': 11, 'came': 61, 'out': 240, 'it': 171, 'that': 335, 'obvious': 230, 'kind': 177, 'fancied': 112, 'up': 358, 'oktoberfest': 234, 'while': 371, 'good': 132, \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(X)\n",
    "# summarize\n",
    "print(len(str(vectorizer.vocabulary_)))\n",
    "print(str(vectorizer.vocabulary_)[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.20350706  7.90825515  7.90825515 ...,  7.50279005  7.90825515\n",
      "  7.90825515]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n",
      "[[ 0.01357063  0.01357063  0.0407119   0.01357063  0.02714126  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.02714126  0.05428253\n",
      "   0.13570632  0.01357063  0.01357063  0.01357063  0.08142379  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.36640707  0.01357063  0.01357063\n",
      "   0.02714126  0.01357063  0.01357063  0.0407119   0.01357063  0.01357063\n",
      "   0.14927696  0.01357063  0.01357063  0.01357063  0.02714126  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.05428253  0.13570632  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.0407119   0.01357063  0.01357063\n",
      "   0.01357063  0.0407119   0.02714126  0.0407119   0.01357063  0.10856506\n",
      "   0.02714126  0.02714126  0.02714126  0.01357063  0.01357063  0.01357063\n",
      "   0.0407119   0.02714126  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.02714126  0.06785316  0.0407119   0.01357063  0.0407119   0.02714126\n",
      "   0.0407119   0.01357063  0.01357063  0.05428253  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.02714126  0.02714126  0.01357063  0.02714126  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.09499443  0.01357063  0.01357063\n",
      "   0.01357063  0.02714126  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.0407119   0.01357063  0.02714126  0.01357063  0.01357063\n",
      "   0.02714126  0.01357063  0.02714126  0.01357063  0.01357063  0.08142379\n",
      "   0.01357063  0.01357063  0.01357063  0.05428253  0.08142379  0.01357063\n",
      "   0.08142379  0.01357063  0.01357063  0.01357063  0.02714126  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.0407119   0.01357063  0.05428253\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.02714126  0.01357063  0.17641822  0.01357063  0.01357063  0.01357063\n",
      "   0.05428253  0.01357063  0.14927696  0.18998885  0.02714126  0.01357063\n",
      "   0.01357063  0.06785316  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.08142379  0.02714126  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.01357063  0.09499443  0.01357063  0.05428253  0.01357063\n",
      "   0.0407119   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.06785316  0.02714126  0.01357063  0.06785316  0.01357063\n",
      "   0.01357063  0.0407119   0.05428253  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.06785316  0.01357063  0.01357063\n",
      "   0.02714126  0.01357063  0.05428253  0.0407119   0.08142379  0.09499443\n",
      "   0.01357063  0.01357063  0.05428253  0.05428253  0.05428253  0.01357063\n",
      "   0.02714126  0.06785316  0.01357063  0.01357063  0.25784201  0.0407119\n",
      "   0.05428253  0.0407119   0.05428253  0.0407119   0.01357063  0.01357063\n",
      "   0.08142379  0.01357063  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.0407119   0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.0407119   0.01357063  0.0407119   0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.02714126  0.01357063  0.01357063  0.06785316  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.02714126  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.01357063  0.05428253  0.01357063\n",
      "   0.05428253  0.01357063  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.01357063  0.02714126  0.01357063  0.0407119   0.01357063  0.02714126\n",
      "   0.01357063  0.01357063  0.01357063  0.02714126  0.01357063  0.01357063\n",
      "   0.02714126  0.02714126  0.01357063  0.02714126  0.01357063  0.01357063\n",
      "   0.01357063  0.0407119   0.01357063  0.02714126  0.0407119   0.0407119\n",
      "   0.01357063  0.08142379  0.01357063  0.01357063  0.01357063  0.08142379\n",
      "   0.36640707  0.01357063  0.01357063  0.02714126  0.02714126  0.01357063\n",
      "   0.27141265  0.01357063  0.01357063  0.01357063  0.01357063  0.20355949\n",
      "   0.05428253  0.01357063  0.01357063  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.02714126  0.08142379  0.01357063\n",
      "   0.01357063  0.02714126  0.10856506  0.01357063  0.16284759  0.01357063\n",
      "   0.02714126  0.02714126  0.01357063  0.01357063  0.01357063  0.02714126\n",
      "   0.0407119   0.01357063  0.21713012  0.01357063  0.01357063  0.01357063\n",
      "   0.01357063  0.01357063  0.01357063  0.02714126  0.01357063  0.02714126]]\n"
     ]
    }
   ],
   "source": [
    "# encode document\n",
    "vector = vectorizer.transform([X[0]])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'smell': 11165, 'soft': 11263, 'hop': 6090, 'aroma': 918, 'with': 13621, 'significant': 10951, 'malt': 7438, 'scents': 10579, 'this': 12373, 'one': 8499, 'smells': 11171, 'very': 13165, 'creamy': 3179, 'taste': 12183, 'and': 760, 'it': 6575, 'is': 6562, 'the': 12317, 'traditional': 12594, 'irish': 6546, 'flavors': 4964, 'come': 2790, 'out': 8606, 'at': 1005, 'tongue': 12522, 'not': 8299, 'like': 7146, 'cream': 3171, 'ale': 629, 'but': 2030, 'close': 2653, 'big': 1452, 'buttery': 2039, 'smooth': 11194, 'hops': 6116, 'are': 896, 'unique': 12939, 'sharp': 10812, 'flavor': 4957, 'an': 750, 'easy': 4133, 'saturated': 10524, 'well': 13435, 'mixed': 7865, 'blend': 1560, 'that': 12312, 'plays': 9177, 'complimenting': 2866, 'second': 10666, 'fiddle': 4818, 'to': 12482, 'base': 1222, 'no': 8248, 'sweetness': 12034, 'finish': 4878, 'nutty': 8357, 'changes': 2388, 'personalities': 9001, 'end': 4289, 'mouthfeel': 8004, 'lightly': 7135, 'carbonated': 2203, 'exceptionally': 4515, 'drinkability': 400\n",
      "236226\n"
     ]
    }
   ],
   "source": [
    "# vectorize with a list of reviews\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "X = df['review'][0:2000]\n",
    "\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(X)\n",
    "# summarize\n",
    "print(str(vectorizer.vocabulary_)[:1000])  # print a slice because this is very long\n",
    "print(len(str(vectorizer.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n",
      "[[ 0.07887912  0.01314652 -0.0657326   0.02629304 -0.0657326  -0.17090475\n",
      "  -0.01314652  0.         -0.28922343  0.01314652  0.10517215  0.01314652\n",
      "   0.28922343 -0.14461171 -0.01314652  0.01314652 -0.02629304 -0.10517215\n",
      "   0.21034431  0.          0.07887912  0.14461171 -0.07887912  0.02629304\n",
      "  -0.21034431  0.07887912 -0.14461171  0.14461171  0.01314652  0.\n",
      "   0.02629304 -0.03943956  0.24978387  0.14461171  0.07887912  0.15775823\n",
      "   0.07887912 -0.02629304  0.23663735  0.13146519 -0.22349083  0.19719779\n",
      "   0.         -0.03943956  0.07887912 -0.36810254  0.36810254 -0.07887912\n",
      "  -0.03943956  0.01314652]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "X = [df['review'][2]]  # start with a long review\n",
    "X2 = [df['review'][0]] # X2 is shorter\n",
    "\n",
    "# create the transform\n",
    "vectorizer = HashingVectorizer(n_features=50)\n",
    "# encode document\n",
    "vector = vectorizer.transform(X)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = df.groupby(['style']).size()\n",
    "styles = counts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Altbier', 'American Adjunct Lager', 'American Amber / Red Ale',\n",
       "       'American Amber / Red Lager', 'American Barleywine',\n",
       "       'American Black Ale', 'American Blonde Ale', 'American Brown Ale',\n",
       "       'American Dark Wheat Ale', 'American Double / Imperial IPA',\n",
       "       ...\n",
       "       'Scotch Ale / Wee Heavy', 'Scottish Ale',\n",
       "       'Scottish Gruit / Ancient Herbed Ale', 'Smoked Beer', 'Tripel',\n",
       "       'Vienna Lager', 'Weizenbock', 'Wheatwine', 'Winter Warmer', 'Witbier'],\n",
       "      dtype='object', name='style', length=104)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorize with a list of reviews\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#  Create X for predictor variables, y for target\n",
    "X = df['review'][0:2000].values\n",
    "y = df['style'][0:2000].values\n",
    "test_X = df['review'][3000:4000].values\n",
    "test_y = df['style'][3000:4000].values\n",
    "\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train_counts = count_vect.fit_transform(X)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X)\n",
    "\n",
    "# Naive Bayes classifier\n",
    "clf = MultinomialNB().fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"   poured from a 650ml bottle,7% abv, 80 ibu's fresh hopped with cascade and centennial with nugget for bittering. l: pours a dark red amber with just a skim of head with minor lacing. s: not much of a nose for me ,some hops and mild spice. t: really smooth well balance red ipa, looks like they used 5 malts and it works well with the fresh hops nice on the bitterness. f: a light carbonation nice mouth feel no alcohol taste at all. o: a really nice fresh hopped red ipa.   \"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ccb1df7424ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classes_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[1;32m    726\u001b[0m                 self.class_log_prior_)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"   poured from a 650ml bottle,7% abv, 80 ibu's fresh hopped with cascade and centennial with nugget for bittering. l: pours a dark red amber with just a skim of head with minor lacing. s: not much of a nose for me ,some hops and mild spice. t: really smooth well balance red ipa, looks like they used 5 malts and it works well with the fresh hops nice on the bitterness. f: a light carbonation nice mouth feel no alcohol taste at all. o: a really nice fresh hopped red ipa.   \""
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(test_X)\n",
    "np.mean(predicted == test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# could use a pipeline to do the same:\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),                      \n",
    "                     ('clf', MultinomialNB()),])\n",
    "text_clf = text_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### start over here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prep the data\n",
    "df = df_copy\n",
    "df = df.drop(['name','brewery'], axis=1)\n",
    "# drop all reviews with < 15 characters\n",
    "df = df[df['review'].map(len) > 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49291\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_id = 0\n",
    "text = df.loc[t_id, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-a38df8ab5db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import summarize, keywords\n",
    "\n",
    "word_scores = keywords(text, words=5, scores=True, split=True, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
